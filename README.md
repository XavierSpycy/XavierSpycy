<img src="https://komarev.com/ghpvc/?username=XavierSpycy&color=blueviolet">

<img src="assets/header.svg">

<img src="assets/chris-ried-python-crop.jpg">
Photo by <a href="https://unsplash.com/@cdr6934?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Chris Ried</a> on <a href="https://unsplash.com/photos/ieic5Tq8YMk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>

<a><img src="https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg" align="right" height="48" width="48" ></a>

<a href="https://git.io/typing-svg">
    <img src="https://readme-typing-svg.herokuapp.com?color=%2336BCF7&center=true&vCenter=true&width=600&lines=ðŸ‘‹++Hi~,+I+am+Jiarui+Xu~;ðŸ‘‹++ä½ å¥½ï½žæˆ‘å«å¾å˜‰ç‘žï½ž;Welcome+to+my+profile!;æ¬¢è¿Žæ¥åˆ°æˆ‘çš„ä¸»é¡µ!;Master's+degree+of+Data+Science;æ•°æ®ç§‘å­¦ç¡•å£«;Machine+learning+specialization;æœºå™¨å­¦ä¹ ä¸“é¡¹;Python+programming+enthusiast;Pythonç¼–ç¨‹çˆ±å¥½è€…;Patience+and+persistence.;æŒä¹‹ä»¥æ’ã€‚" alt="Typing SVG">
</a>

<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
  <a href="https://github.com/anuraghazra/github-readme-stats" style="margin-right: 10px;">
    <img height="180" src="https://github-readme-stats.vercel.app/api?username=XavierSpycy&show_icons=true&theme=default&hide=issues"/>
  </a>
  <a href="https://github.com/anuraghazra/github-readme-stats">
    <img height="180" src="https://github-readme-stats.vercel.app/api/top-langs/?username=XavierSpycy&layout=donut">
  </a>
</div>

```mermaid
graph TD;
    DomainKnowledge[Domain Knowledge]-->MachineLearning[Machine Learning];
    MachineLearning[Machine Learning]-->StatisticalLearning[Statistical Learning];
    MachineLearning[Machine Learning]-->DeepLearning[Deep Learning];
    DomainKnowledge[Domain Knowledge]-->BackendDevelopment[Backend Development];
    DeepLearning[Deep Learning]-->ImageClassification[Image Classification];
    ImageClassification[Image Classification]-->LabelNoise[Label Noise];
    DeepLearning[Deep Learning]-->NaturalLanguageProcessing[Natural Language Processing];
    NaturalLanguageProcessing[Natural Language Processing]-->TopicModeling[Topic Modeling];
    NaturalLanguageProcessing[Natural Language Processing]-->LLMApplication[LLM Application];
    DeepLearning[Deep Learning]-->Multimodality[Multimodality];
    Multimodality[Multimodality]-->ImageTextClassification[Image-Text Classification];
    Multimodality[Multimodality]-->VisualQuestionAnswering[Visual Question Answering];
   ```

| |Skills|
|-|-|
| **Domain Knownledge**| ![](https://img.shields.io/badge/Machine-Learning-01D277?style=flat&logoColor=white&labelColor=ADD8E6) ![Deep Learning](https://img.shields.io/badge/Deep-Learning-01D277?style=flat&logoColor=white&labelColor=0000FF) ![Natural Language Processing](https://img.shields.io/badge/Natural%20Language%20Processing-4C8CBF?style=flat&logoColor=white) ![Software Development](https://img.shields.io/badge/Software%20Development-FF6600?style=flat&logoColor=white) ![Multimodality Learning](https://img.shields.io/badge/Multimodality-Learning-01D277?style=flat&labelColor=lightyellow)|
| **Language**| ![Python](https://img.shields.io/badge/Python-4C8CBF?logo=data:image/svg+xml;base64,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)|
| **Data Analysis**| ![NumPy](https://img.shields.io/badge/-NumPy-4C8CBF?style=flat&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/-Pandas-000077?style=flat&logo=pandas&logoColor=white) ![SciPy](https://img.shields.io/badge/-SciPy%20-white?style=flat&logo=scipy&logoColor=004091) ![Matplotlib](https://img.shields.io/badge/matplotlib-white?logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjgiIGhlaWdodD0iMTI4IiBzdHJva2U9IiM3NzciIGZpbGwtb3BhY2l0eT0iLjgiPgo8cGF0aCBmaWxsPSIjRkZGIiBkPSJtNjMsMWE2Myw2MyAwIDEsMCAyLDB6bTAsMTRhNDksNDkgMCAxLDAgMiwwem0wLDE0YTM1LDM1IDAgMSwwCjIsMHptMCwxNGEyMSwyMSAwIDEsMCAyLDB6bTAsMTRhNyw3IDAgMSwwIDIsMHptNjQsN0gxbTEwOC00NS05MCw5MG05MCwwLTkwLTkwbTQ1LTE4djEyNiIvPgo8cGF0aCBmaWxsPSIjRjYwIiBkPSJtNTAsOC0yMCwxMCA2OCw5MiAxMC0xMEw2NCw2NHoiLz4KPHBhdGggZmlsbD0iI0ZDMCIgZD0ibTE3LDUwdjI4TDY0LDY0eiIvPgo8cGF0aCBmaWxsPSIjN0Y3IiBkPSJtNjQsNjQgNiwzNUg1OHoiLz4KPHBhdGggZmlsbD0iI0NGMyIgZD0ibTY0LDY0IDEzLTQwIDksNXoiLz4KPHBhdGggZmlsbD0iIzA0RiIgZD0ibTY0LDY0IDE0LTYgMSw0emwtMjYsMTMgMyw0eiIvPgo8L3N2Zz4=)|
| **Databases**| ![MySQL](https://img.shields.io/badge/MySQL-white?logo=data:image/svg+xml;base64,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)|
| **Self-developed package**| [![mlforce](https://img.shields.io/badge/mlforce-green)](https://pypi.org/project/mlforce/) ![Machine Learning Force](https://img.shields.io/pypi/v/mlforce)|
| **Statistic Learning Tools**| ![R programming](https://img.shields.io/badge/R-525252?style=for-the-badge&logo=R) ![R Studio](https://img.shields.io/badge/RStudio-27338e?style=for-the-badge&logo=RStudio&logoColor=white)             |
| **Machine Learning Libraries** |   ![Scikit Learn](https://img.shields.io/badge/Scikit-Learn-blue?style=flat&logoColor=black&labelColor=orange)|
| **Deep Learning Frameworks** |  ![PyTorch](http://img.shields.io/badge/-PyTorch-4F004F?style=flat-square&logo=pytorch&logoColor=FF0000) ![TensorFlow](http://img.shields.io/badge/-TensorFlow-eee?style=flat-square&logo=tensorflow&logoColor=FF6F00) ![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-929292) |
| **Visualization techniques**| ![Tableau](https://img.shields.io/badge/-Tableau-FF0000?style=flat&logo=tableau&logoColor=white) ![PowerBI](https://img.shields.io/badge/-PowerBI-FF6F00?style=flat&logo=powerbi&logoColor=white) ![D3](https://img.shields.io/badge/-D3.js%20-EEEE00?style=flat&logo=d3.js&logoColor=white) ![Tulip](https://img.shields.io/badge/-Tulip%20-00AA00?style=flat&logo=Tulip&logoColor=white) ![yEd](https://img.shields.io/badge/-yEd%20-00000FF?style=flat&logo=yEd&logoColor=white) ![Gephi](https://img.shields.io/badge/-Gephi%20-4F004F?style=flat&logo=Gephid&logoColor=white)

<details>
  <summary><h2>ðŸ“– Curriculum Vitae</h2></summary>
    <p>
    <a href="assets/Jiarui_XU_CV.pdf">English</a> | 
    <a href="assets/Jiarui_XU_CV__zh_CN_.pdf">ä¸­æ–‡ç‰ˆ</a>
    </p>
</details>

<details>
  <summary><h2>ðŸŒŠ Experiences</h2></summary>
  <ul>
    <li>
      Ressearch Interests : LLM Applications / Multimodality Learning
    </li>
    <li>
      Research:
      <ol>
        <li>
          Cross-modal medical image representation learning (<u><em>USYD Engineering VRI Scholarship</em></u>)
        </li>
        <li>
          <em>Top</em>ic <em>M</em>odeling for the <em>E</em>volution through <em>D</em>escriptions of <em>A</em>pplications <em>L</em>ongitudina (<em>TopMEDAL</em>)
        </li>
      </ol>
    </li>
    <li>
      Internship:
      <ul>
        <li>
          <code>AIGC Algorithm Intern</code> &#x40; <img src="https://img.shields.io/badge/FunPlus-orange?logo=data:image/svg+xml;base64,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">:
        </li>
        <ul>
          <li>
            Department of AI Tech
          </li>
          <li>
            2023.12 ~ 2024.02
          </li>
        </ul>
        <li>
          <code>Vacation Research Intern</code> &#x40; <img src="https://img.shields.io/badge/USYD-white?logo=data:image/svg+xml;base64,<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" id="Layer_1" data-name="Layer 1" viewBox="250.0 250.0 500.0 500.0"><ns0:defs><ns0:style>.cls-1{fill:#373636;}</ns0:style></ns0:defs><ns0:path class="cls-1" d="M512.36,570.4h35v-5.12h-35Zm0,14.46h35v-5.13h-35Zm0-28.91h35v-5.13h-35Zm-24.72,9.33h-35v5.12h35Zm0,14.45h-35v5.13h35Zm0-28.91h-35V556h35Zm55-92.32c-14-.93-28.44-.93-42.89-.93-14,0-28.44.47-42.43.93v70.41H323.06c5.59,33.57,19.11,65.27,39.16,91.38a14.81,14.81,0,0,1,12.12-6.06H457.8v73.21A160.6,160.6,0,0,0,500.23,693v0a158,158,0,0,0,42.43-5.59V614.23h83.46a14.81,14.81,0,0,1,12.13,6.06,211.49,211.49,0,0,0,39.16-91.38H542.66V458.5Zm-67.14,21.92,18.19,8.39,6.52-18.65,6.53,19.12,17.72-8.86-8.86,18.18,18.65,6.53-19.12,6.53L524,529.37,505.83,521l-6.53,18.65-7-19.11-16.79,9.32,8.39-18.18-18.65-6.53,19.12-6.53c-.47-.47-8.86-18.18-8.86-18.18Zm-63.88,116.1-17.71-8.86-6.53,19.11-6.53-18.65-18.18,8.4,8.86-17.72-19.12-6.53,18.65-6.53-8.86-18.18,17.72,8.86,6.53-19.12L393,556l18.19-8.39-8.86,17.72,19.12,7-18.65,6.53Zm28.91-1.4h-7.92v-5.6h7.92Zm0-15.39h-7.92v-5.6h7.92Zm0-15.39h-7.92v-5.59h7.92v5.59Zm0-15.85h-7.92V542.9h7.92Zm4.2,46.63v-56h37.77a13.73,13.73,0,0,1,14,14v46.63a13.93,13.93,0,0,0-10.72-5.13C484.85,595.12,455.94,595.12,444.75,595.12Zm79.73,72.73-18.19-8.39-6.52,18.65-7-19.12-17.25,8.86,8.86-18.18-18.65-6.53,19.12-7-9.33-17.72,18.19,8.39,6.52-18.65,7,19.12,17.71-8.86-8.39,18.18,18.65,6.53-19.11,7Zm63.41-120.76,18.18,8.39,6.53-18.65,7,19.12,17.72-8.86-8.86,18.19,18.65,6.52L628,578.33l8.86,17.72-18.19-8.39-6.53,18.65-6.06-18.65-17.71,8.86,8.85-18.19-18.65-6.53,19.12-7c-.93,0-9.79-17.72-9.79-17.72Zm-28.44-4.19h7.92v5.59h-7.92Zm0,15.38h7.92v5.6h-7.92Zm0,15.39h7.92v5.59h-7.92Zm0,15.85h7.92v5.6h-7.92Zm-4.2-50.35v56H514.69A13.25,13.25,0,0,0,504,600.25V553.62a13.74,13.74,0,0,1,14-14h2.33c-.46-.46,35-.46,35-.46Zm69-237.8c-34.51-7.46-80.2-14.45-124.49-14.45-66.21,0-135.68,16.32-166.46,24.71-6.06,1.4-10.72,2.8-13.52,3.73V465.5c20-3.27,102.11-15.86,180-15.86s159.92,12.59,180,15.86V314.9c-2.8-.94-7-1.87-13.52-3.73-9.79-2.34-24.71-6.07-42-9.8Zm-187.9,15.86c2.79-.47-3.27-5.13.46-5.13,2.33,0,10.73,0,16.79,3.26,1.4.47,1.86-1.86,4.19-3.26,0,0,.94-.47,1.4,0,2.33,1.4,3.27,3.73,4.67,3.26,6.06-2.8,14.45-2.8,16.78-3.26,4.2-.47-1.86,4.19.47,5.13,14,3.26,24.24,14.92,24.24,29.37A32.44,32.44,0,0,1,503,358.26c-.93,1.86-2.8-3.73-3.73-.47-.47,5.6-1.86,9.79-5.13,15.85-2.8,5.6-7.92-6.06-9.32-2.79-2.8,5.59-8.86,7.46-13.52,8.39-.47,0-.94,0-.47-.47a5.15,5.15,0,0,0,1.4-3.26,1.44,1.44,0,0,1,.46-.93,11,11,0,0,0,6.53-8.4c.93-3.26,2.33-8.39,4.2-11.65,3.73-6.53-.93-14.92.46-16.79a9.15,9.15,0,0,0,4.2-7.92,9.86,9.86,0,0,0-9.79-9.8,9.08,9.08,0,0,0-7,3.27l-.47.46a12.48,12.48,0,0,0-2.33,2.8,2.52,2.52,0,0,0,.93,3.73c6.53,1.87,10.72,16.32,7.93,21-1.4,2.34-4.67,10.26-4.67,12.13a5.18,5.18,0,0,1-5.12,5.13,5.72,5.72,0,0,1-5.13-3.27c1.86-.93,5.59-3.73,5.59-6.06l-.93-7.93c3.26-.46,4.66-2.33,5.13-5.12.46,0,.46-.47.93-.47.93-.93,1.87-3.73-.47-3.26-3.26.46-7,.46-10.72,1.39a1,1,0,0,0-.93.94c0,.46,1.86,10.25,2.33,12.59,0,.46,0,.46-.47.46-1.4,0-4.19-.46-4.66-.46a19.54,19.54,0,0,0-4.66.46.46.46,0,0,1-.47-.46c.47-2.34,2.8-12.13,2.8-12.13v-.93c-.47-.93-10.26-1.86-11.66-1.86a1.74,1.74,0,0,0-1.4.46c-.93,1.4.94,2.8,1.87,3.27.46,2.79,1.86,4.66,5.13,5.12,0,.47-.94,7.93-.94,7.93,0,2.8,3.73,4.66,6.07,6.06l.46.47a5.74,5.74,0,0,1-5.13,3.26,5.18,5.18,0,0,1-5.13-5.13c0-1.86-3.73-10.25-4.66-12.59-2.8-5.12,1.4-19.58,8.39-21a2.23,2.23,0,0,0,.94-3.73c-2.8-2.8-6.06-6.53-10.26-6.53a9.85,9.85,0,0,0-9.79,9.8c0,6.06,4.66,7,4.19,8.86-1.86,5.59-1.86,11.65.47,15.85,1.87,2.8,3.26,7.92,4.2,11.19a11.91,11.91,0,0,0,5.59,8.39c1.4.93.93,1.87,1.4,3.26.47.47.93.94.93,1.4.47.47,0,.47-.46.47-4.67-.47-11.19-2.33-14-8.39-1.4-3.27-6.53,7.92-9.33,2.79a43.15,43.15,0,0,1-5.59-15.85c-.93-3.26-2.8,2.33-3.73.47a29.84,29.84,0,0,1,22.85-41ZM476.45,327v-.93a3.56,3.56,0,0,1,2.34-.94,4.29,4.29,0,0,1,2.79,7.46c-.46.47-.93,0-.93-.46A14.48,14.48,0,0,0,476.45,327Zm-9.79,48c-.93,2.8-4.66,1.87-7,3.27h-.93c-1.87-1.87-5.6-.94-7-3.73,0,0,0-.94.47-.94a10.35,10.35,0,0,0,7-3.73.66.66,0,0,1,.94,0c1.39,1.87,3.73,2.8,6.06,3.27.46.93.93,1.4.46,1.86Zm-28.44-42a.64.64,0,0,1-.93,0,4.24,4.24,0,0,1-1.4-3.26,4.17,4.17,0,0,1,4.2-4.2,3.31,3.31,0,0,1,2.79,1.4.64.64,0,0,1,0,.93A10.11,10.11,0,0,0,438.22,333.08ZM400,388.1c-2.8,0-4.2.93-6.06,2.33-1.4.93-1.87-1.87,0-7,1.4-4.2-7-6.53-8.86-4.67-2.8,2.33-9.79,6.53-16.79-.93-1.4-1.4,3.27-.93,3.27-2.33.46-1.87,2.33-2.8,2.79-3.73a1.16,1.16,0,0,0-.46-1.87,7.15,7.15,0,0,1-4.2-8.39c0-.46-3.73-.93-2.33-1.86,6.53-6.06,13.52-2.33,16.32-.47.47,0,1.4.47,1.4-.47,0-1.86-.93-3.26,3.26-6.52.93-.47-2.33-3.27,0-3.27,13.52,3.27,7.46,17.25,10.26,20.05,5.13,4.66,17.72,8.39,29.37,10.73a25.91,25.91,0,0,1,5.6,1.86c9.32,4.66,15.38,4.2,20.51,2.33,1.87-.46,1.4,1.4.94,1.87-18.65,17.71-33.11,13.52-38.24,10.25-3.73-2.33-10.72-2.33-14,2.34-.47.46-1.4.93-1.87-.47-.93-3.26,0-5.6.93-8.39.47-.94-.93-1.4-1.86-1.4ZM579.5,404.88c-2.33,2.33-7,4.67-14,4.2a8.28,8.28,0,0,0-5.13,1.4c-.93.93-.93,1.4-.93,1.86a4.47,4.47,0,0,0,.93,4.2c.93.93.47,1.87-.93,1.87-1.4.46-2.8.46-5.6-.94-1.4-.46-1.86,0-1.86.94-.47,1.39.46,3.26,2.33,4.66.93.93.93,1.86-.93,2.33-2.8.93-5.13-.47-8.86-2.33-2.33-1.4-4.2-1.4-5.6.46-.93.94-.93,1.87-.46,2.34,1.39,1.39,2.33,4.66-1.4,9.32-1.4,1.4-2.8-2.8-3.73-2.33-5.13,2.33-9.33-.93-11.19-2.8-.47-.46-.94-.46-1.87,0-2.8,1.87-8.39,4.66-10.26-.46-.46-.94-3.26.93-3.26-.47,0-8.39,7.46-9.79,10.26-10.26.93,0,.93-.46.46-1.4-1.39-1.86-2.79-4.19-1.86-6.53.47-1.86-4.2-2.33-2.33-3.26,9.79-4.66,14.92,4.2,16.78,5.13,2.8,1.4,15.39-2.33,16.79-9.33.47-1.39-2.8-1.86-6.06-2.79-.47,0-.94-.94,0-1.87,7.46-5.59,13.52-13.05,27.51-14.45a2.11,2.11,0,0,1,2.33,1.86,22.89,22.89,0,0,0,1.86,6.06,19.77,19.77,0,0,0,7,8.86,3.57,3.57,0,0,1,0,3.73Zm57.35-4.66c1.4.47,1.4,1.4.46,2.33S635,404,631.72,404c-1.4,0-1.4.93-1.4,1.4,0,1.4,1.86,2.8,4.2,2.8,1.39.46,1.39,1.4.46,2.33-1.86,1.86-4.66,1.86-9.32,1.86-4.2,0-7.46,5.13-5.13,7,1.86,1.4,5.13,4.66,2.33,13.52-.93,2.8-2.33-2.33-3.73-1.4-3.73,2.33-6.53-.47-8.39-2.33a1,1,0,0,0-1.87,0c-1.4,2.33-5.13,7-12.59,2.8-1.4-.94-5.13,2.33-5.13.93-1.4-6.06,1.87-9.33,4.2-11.19.47,0,1.4-1.4-.47-1.4-2.33,0-5.59-.93-6.06-4.2,0-.46-3.26-.46-3.26-1.39.93-4.2,10.26-7.47,16.78-3.27,5.6,3.73,12.59-8.86,7.46-14.45-3.73-4.2-24.71,7.46-31.7-7.46-2.8-6.06.93-11.19-2.33-11.66-2.8-.47-16.32-3.26-30.78,8.39-24.71,20-51.75,8.86-58.28,4.67a1,1,0,0,0-1.4,1.39,8.82,8.82,0,0,1-.46,7c-2.8,3.73-11.66,7.92-13.06,8.39-10.26,3.26-9.32,11.19-8.39,14.46.47.93,0,1.86-1.4,1.39-3.26-.46-9.79-2.33-12.12-8.86-.47-.93-.94-.93-1.87,0-3.73,2.8-2.33,7-1.4,8.4.47.93,0,1.4-.93,1.4-3.73.46-6.06-3.73-9.32-3.27-1.87,0-4.2,1.87-5.6,2.8a2.06,2.06,0,0,0-.47,2.33C434,438,428,438.45,427.5,438s0-2.33-1.87-2.33c-6.06.46-7.92-3.73-8.39-7,0-.93-.47-1.4-1.4-.93-2.33,1.87-8.39,5.13-12.12,0-.47-.47-2.33,0-3.27.47s-.93-.94-.93-1.4A12.53,12.53,0,0,1,407,416.07c.93-.46.93-.93.47-1.4-1.87-1.39-5.6-4.66-4.2-7.92,0-.47-2.8-1.87-2.33-2.33,7.46-5.13,16.32,3.26,17.72,4.19s7.92,1.4,24.71-8.39c10.72-6.06,16.32-10.72,19.12-14.45a2.88,2.88,0,0,1,2.33-1.4c6.53,0,13.52-1.4,18.65-5.6a1.54,1.54,0,0,1,2.33,0c9.79,6.53,14.45-7.92,16.32-14.92.46-1.4.46-2.33,1.86-2.79,35.44,1.86,102.11,1.39,102.11,1.39s8.86.47,8.4-4.66c-.47-8.86-37.3-8.39-64.35-4.66-9.79,1.4-24.24,2.33-32.64-.93a14.13,14.13,0,0,1-7.92-6.53,10,10,0,0,1-.93-7.93,24.51,24.51,0,0,1,2.33-5.13c7-10.72,23.31-11.65,28-11.65a2.44,2.44,0,0,0,1.87-.94c.46-2.33,2.33-8.39,9.32-8.39,1.87,0,3.73-.93,5.13-1.4.93-.46,1.4,0,.93.47a4,4,0,0,1-1.39,2.8c-4.67,4.19-4.2,6.06-3.27,6.52a.64.64,0,0,0,.93,0c14.46-12.58,22.85-4.19,25.18-1.39.47.46.47,1.39-.46,1.39-9.8,2.34-13.53,10.73-33.57,9.33-2.34,0-18.66-.93-23.78,6.53-2.8,4.19-.94,8.39,7.92,10.26,6.53,1.39,22.38-.94,29.84-1.4,7-.47,38.7-4.67,55,0,7,1.86,17.25,7.46,14.92,18.18-1.4,6.53-7.93,9.33-7.93,9.33s-18.18,12.58,14.46,13.05c10.26,0,0,8.39-.47,10.72,0,1.87,1.87,3.27,3.27,4.2Zm-59.22-70.4a7.39,7.39,0,0,0-3.73,1.4c-2.8,1.86-14.45,7-18.18.93,0,0,8.39-.47,13.52-5.13,0,0,5.59-1.87,9.32.93-.46.93,0,1.87-.93,1.87ZM500.23,265c-110.5,0-220.54,29.37-220.54,29.37V441.25c0,132.42,94.65,270,220.08,293.74,130.08-25.64,220.54-161.32,220.54-293.74V294.38S628.45,265,500.23,265ZM687.67,494.87c0,107.71-82.06,205.62-187.44,205.62-105.84,0-187.9-97.91-187.9-205.62V309.3l2.8-.93S410.25,279,499.77,279,684.4,308.37,684.4,308.37l2.8.93V494.87Z" /></ns0:svg>">
          <ul>
            <li>
              Faculty of Engineering
            </li>
            <li>
              2024.06 ~ 2024.07
            </li>
          </ul>
        </li>
      </ul>
  </ul>
</details>

<details>
  <summary>
    <h2>ðŸš€ Projects</h2>
  </summary>
  <details>
    <summary>
      <h3><img src="https://img.shields.io/badge/NumPy-blue?style=flat&logo=numpy" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
    <p align="center">
      <img src="assets/google-deepmind.jpg" width="500" height="auto">
    </p>
    <p>
      Photo by <a href="https://unsplash.com/@googledeepmind?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Google DeepMind</a> on <a href="https://unsplash.com/photos/LaKwLAmcnBc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
    </p>
    <details>
      <summary id="star-self-developed-library-using-numpy">
        <h3>ðŸŒŸSelf-Developed Library using NumPy</h3><a href="https://github.com/XavierSpycy/MLForce">&#x2197;</a>
      </summary>
      <p>
        My NumPy-based projects have been successfully integrated into my own open-source Python library, named <a href="https://pypi.org/project/mlforce/"><code>MLForce</code></a>. This library is also readily accessible on the <a href="https://pypi.org/project/mlforce">PyPI Community</a>.
      </p>
    </details>
    <details>
      <summary>
        <h3>ðŸŒŸMultilayer Perceptron from Scratch using NumPy<a href="https://github.com/XavierSpycy/NumPyMultilayerPerceptron">&#x2197;</a></h3>
        <p>
      </summary>
        A robust implementation of multilayer perceptrons, entirely built upon the powerful NumPy library.
        </p>
        <p>Advantages of our implementation:
          <ul>
            <li>
              <details>
                <summary>Easy to construct</summary>
                <p>
                  <pre><code class="language-python">layers = [
      Input(input_dim=2),
      Dense(units=4, activation='leaky_relu', init='kaiming_normal', init_params={'mode': 'out'}),
      Dense(units=3, activation='hardswish', init='xavier_normal'),
      Dense(units=2, activation='relu', init='kaiming_normal', init_params={'mode': 'in'}),
      Dense(units=1, activation='tanh', init='xavier_uniform')
  ]
  mlp = MultilayerPerceptron(layers)</code></pre>
                </p>
              </details>
            </li>
            <li>
              <details>
                <summary>Easy and stable to train</summary>
                <p>
                  <pre><code class="language-python">mlp.compile(optimizer='Adam',
              metrics=['MeanSquareError'])
  mlp.fit(X, y, epochs=3, batch_size=8, use_progress_bar=True)</code></pre>
                </p>
                <p align="center">
                  <img src="https://github.com/XavierSpycy/NumPyMultilayerPerceptron/blob/main/figures/toy_loss.png">
                </p>
                <div align="center" style="font-weight: bold;">
                  Loss
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary>
                  Great results
                </summary>
                <p align="center">
                  <img src="https://github.com/XavierSpycy/NumPyMultilayerPerceptron/blob/main/figures/toy_decision_boundary.png">
                </p>
                <div align="center" style="font-weight: bold;">
                  Decision boundary
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary>
                  Capability of dealing with complex datasets (10 classes, 128 features, 50,000 samples)
                </summary>
                <p align="center">
                  <img src="https://github.com/XavierSpycy/NumPyMultilayerPerceptron/blob/main/figures/10classes.png">
                </p>
                <div align="center" style="font-weight: bold;">
                  Smooth optimization procedure in 600 epochs
                </div>
              </details>
            </li>
    </details>

  <details>
    <summary>
      <h3>ðŸŒŸNon-negative Matrix Factorization using NumPy<a href="https://github.com/XavierSpycy/NumPyNMF">&#x2197;</a></h3>
    </summary>
    <p>
      This project implements nine different Non-negative Matrix Factorization (NMF) algorithms and compares the robustness of each algorithm to five various types of noise in real-world data applications.
    </p>
    <ul>
      <li>
      <details>
        <summary>
          Well-reconstructed effects
        </summary>
        <p align="center">
          <img src="https://github.com/XavierSpycy/NumPyNMF/blob/main/figures/pin.png">
        </p>
        <div align="center" style="font-weight: bold;">
          Image reconstruction
        </div>
      </details>
      </li>
      <li>
      <details>
        <summary>Sufficient experiments</summary>
        <p>
          We conduct a seires of experiments, thus when developing your own algorithms, these results could act as a baseline. The results of the experiments (2 datasets &times; 5 noise types &times; 2 noise levels &times; 5 random seeds implicitly) are displayed in the repository.
        </p>
      </details>
      </li>
      <li>
      <details>
        <summary>Flexible development</summary>
        <p>
          Our development framework empowers you to effortlessly create your own NMF algorithms with minimal Python scripting.
        </p>
      </details>
      </li>
      <li>
      <details>
        <summary>Mature pipeline</summary>
        <p>
          Our framework offers well-established pipelines, accommodating both standard and customized NMF tests. 
        </p>
        <p>
          For personalized NMF models, the <code>nmf</code> parameter accepts a <code>BasicNMF</code> object. You can seamlessly insert your own NMF model into our pipeline to evaluate its performance.
        </p>
      </details>
      </li>
      <li>
      <details>
        <summary>Multiprocessing experiments</summary>
        <p>
          We've harnessed the power of multiprocessing for extensive experiments, significantly enhancing efficiency. This approach has halved the overall experiment duration, reducing it to 30% ~ 50% of the time it would take to run each experiment sequentially.
        </p>
        <p>
          For a comprehensive analysis of your algorithm, our platform enables conducting multiple experiments across various datasets:
        </p>
        <pre><code>from algorithm.pipeline import Experiment

  exp = Experiment()
  exp.choose('L1NormRegularizedNMF')
  exp.execute()</code></pre>
      </details>
      </li>
      <li>
      <details>
        <summary>Interactive algorithm interface</summary>
        <p align="center">
          <img src="https://github.com/XavierSpycy/NumPyNMF/blob/main/figures/app_screen_shoot.jpg">
        </p>
        <p align="center">
          <img src="https://github.com/XavierSpycy/NumPyNMF/blob/main/figures/app_screen_shoot_2.jpg">
        </p>
        <div align="center" style="font-weight: bold;">
          Demo
        </div>
        <p>
          Note that the initial parameter in these experiments can also be <code>BasicNMF</code> object, allowing the direct integration of your custom NMF model for thorough evaluation and testing.
        </p>
      </details>
      </li>
    </ul>
  <b>
    DON'T HESITATE TO DEVELOP YOUR OWN ALGORITHM!!!
  </b>
  </details>
  </details>
  <details>
    <summary>
      <h3><img src="http://img.shields.io/badge/-PyTorch-4F004F?style=flat-square&logo=pytorch&logoColor=FF0000" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
    <p align="center">
      <img src="assets/alex-knight-machinelearning.jpg" width="500" height="auto">
    </p>
    Photo by <a href="https://unsplash.com/@agk42?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Alex Knight</a> on <a href="https://unsplash.com/photos/white-robot-near-brown-wall-2EJCSULRwC8?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
    <details>
      <summary id="star-emnist-handwritten-character-classification">
        <h3>ðŸŒŸEMNIST Handwritten Character Classification</h3><a href="https://github.com/XavierSpycy/EMNIST-Classifier">&#x2197;</a>
      </summary>
      <p>
        This project aims to reproduce various convolutional neural networks and modify them to our specific requirements.
      </p>
      <div align="center">
    <table style="text-align: center;">
      <caption>Performance of different CNNs on the training set</caption>
      <tr>
        <td></td>
        <td align="center">AlexNet</td>
        <td align="center">VGGNet</td>
        <td align="center">SpinalNet</td>
        <td align="center">ResNet</td>
      </tr>
      <tr>
        <td align="center">Accuracy</td>
        <td align="center">87.95%</td>
        <td align="center">89.80%</td>
        <td align="center">87.15%</td>
        <td align="center">89.28%</td>
      </tr>
      <tr>
        <td align="center">Precision</td>
        <td align="center">87.62%</td>
        <td align="center">90.01%</td>
        <td align="center">86.18%</td>
        <td align="center">89.24%</td>
      </tr>
      <tr>
        <td align="center">Recall</td>
        <td align="center">87.95%</td>
        <td align="center">89.80%</td>
        <td align="center">87.15%</td>
        <td align="center">89.28%</td>
      </tr>
      <tr>
        <td align="center">F1 score</td>
        <td align="center">86.59%</td>
        <td align="center">88.42%</td>
        <td align="center">85.28%</td>
        <td align="center">88.30%</td>
      </tr>
    </table>
    </div>
    <div align="center">
    <table style="text-align: center;">
      <caption>Performance of different CNNs on the test set</caption>
      <tr>
        <td></td>
        <td align="center">AlexNet</td>
        <td align="center">VGGNet</td>
        <td align="center">SpinalNet</td>
        <td align="center">ResNet</td>
      </tr>
      <tr>
        <td align="center">Accuracy</td>
        <td align="center">86.96%</td>
        <td align="center">87.24%</td>
        <td align="center">85.92%</td>
        <td align="center">86.88%</td>
      </tr>
      <tr>
        <td align="center">Precision</td>
        <td align="center">85.55%</td>
        <td align="center">86.43%</td>
        <td align="center">85.92%</td>
        <td align="center">86.88%</td>
      </tr>
      <tr>
        <td align="center">Recall</td>
        <td align="center">86.96%</td>
        <td align="center">87.24%</td>
        <td align="center">85.92%</td>
        <td align="center">86.88%</td>
      </tr>
      <tr>
        <td align="center">F1 score</td>
        <td align="center">85.58%</td>
        <td align="center">85.66%</td>
        <td align="center">84.07%</td>
        <td align="center">85.68%</td>
      </tr>
    </table>
    </div>
    <p align="center">
      <img src="https://github.com/XavierSpycy/EMNIST-Classifier/blob/main/outputs/predictions_short.png">
    </p>
    <div align="center" style="font-weight: bold;">
      Effects of VGGNet
    </div>
    </details>
    <details>
    <summary>
      <h3>ðŸŒŸCAT: A Visual-Text Multimodal Classifier</h3><a href="https://github.com/XavierSpycy/CAT-ImageTextIntegrator">&#x2197;</a>
    </summary>
    <p>
      This project involves a multi-label multi-classification problem. We deployed four pre-trained image models and two pre-trained text models. To enhance performance, we developed 12 multi-modal models using self-attention and cross-attention mechanisms. The project poster showcases some valuable techniques and intriguing discoveries.
    </p>
    <p align="center">
      <img src="https://github.com/XavierSpycy/CAT-ImageTextIntegrator/blob/main/outcomes/CAT-2.jpeg">
    </p>
    <div align="center" style="font-weight: bold;">
      CAT (Convolution, Attention and Transformer) architecture
    </div>
    <p align="center">
      <img src="https://github.com/XavierSpycy/CAT-ImageTextIntegrator/blob/main/outcomes/poster.jpg">
    </p>
    <div align="center" style="font-weight: bold;">
      Project Poster
    </div>
  </details>
  <details>
    <summary>
      <h3>ðŸŒŸRobust Traniners for Noisy Labels</h3><a href="https://github.com/XavierSpycy/Robust-Trainers-for-Noisy-Labels">&#x2197;</a>
    </summary>
    <p>
      This project is an experimental repository focusing on dealing with datasets containing a high level of noisy labels (50% and above). This repository features experiments conducted on the <code>FashionMNIST</code> and <code>CIFAR</code> datasets using the <code>ResNet34</code> as the baseline classifier.
    </p>
    <p>
      The repository explores various training strategies (<code>Trainer</code> objects), including <code>ForwardLossCorrection</code>, <code>CoTeaching</code>, <code>JoCoR</code>, and <code>O2UNet</code>. Specifically, for datasets with unknown transition matrices, <code>DualT</code> is employed as the Transition Matrix Estimator.
    </p>
    <ul>
      <li>
        <details>
          <summary>Meaningful Loss Trends</summary>
          <p align="center">
            <img src="https://github.com/XavierSpycy/Robust-Trainers-for-Noisy-Labels/blob/main/figures/loss_correction_trend.png">
          </p>
          <div align="center" style="font-weight: bold;">
            Loss Trend 1
          </div>
          <p align="center">
            <img src="https://github.com/XavierSpycy/Robust-Trainers-for-Noisy-Labels/blob/main/figures/co_teaching_trend.png">
          </p>
          <div align="center" style="font-weight: bold;">
            Loss Trend 2
          </div>
        </details>
      </li>
      <li>
        <details>
          <summary>Persuasive Results</summary>
          <div align="center">
            <h5>FashionMNIST0.5</h5>
              <table>
                <tr>
                  <th colspan="3">Actual Transition Matrix</th>
                  <th colspan="3">Estimated Transition Matrix</th>
                </tr>
                <tr>
                  <td>0.5</td><td>0.2</td><td>0.3</td><td>0.473</td><td>0.209</td><td>0.309</td>
                </tr>
                <tr>
                  <td>0.3</td><td>0.5</td><td>0.2</td><td>0.306</td><td>0.485</td><td>0.232</td>
                </tr>
                <tr>
                  <td>0.2</td><td>0.3</td><td>0.5</td><td>0.221</td><td>0.306</td><td>0.460</td>
                </tr>
              </table>
          </div>
          <div align="center">
            <h5>FashionMNIST0.6</h5>
              <table>
                <tr>
                    <th colspan="3">Actual Transition Matrix</th>
                    <th colspan="3">Estimated Transition Matrix</th>
                </tr>
                <tr>
                  <td>0.4</td><td>0.3</td><td>0.3</td><td>0.407</td><td>0.295</td><td>0.298</td>
                </tr>
                <tr>
                  <td>0.3</td><td>0.4</td><td>0.3</td><td>0.297</td><td>0.394</td><td>0.308</td>
                </tr>
                <tr>
                  <td>0.3</td><td>0.3</td><td>0.4</td><td>0.301</td><td>0.310</td><td>0.388</td></tr>
                </tr>
              </table>
          </div>
        </details>
      </li>
    </ul>
  </details>
  <details>
    <summary>
      <h3>
        ðŸŒŸTransformers for Tabular Data<a href="https://github.com/XavierSpycy/tabtransformers">&#x2197;</a>
      </h3>
    </summary>
    <p>
      A PyTorch-based implementation that leverages Transformer architectures to enhance the handling and design of tabular data.
    </p>
  </details>
  <details>
    <summary>
      <h3>ðŸŒŸMultiCLIP: Multimodal-Multilabel-Multistage Classification using Language Image Pre-training<a href="https://github.com/XavierSpycy/MultiCLIP">&#x2197;</a></h3>
    </summary>
    <p>
      A framework for multimodal-multilabel-multistage classification utilizing advanced pretrained models like CLIP and BLIP. 
    </p>
    <p>
      Diagrams of implementation:
    </p>
    <p align="center">
      <img src="https://github.com/XavierSpycy/MultiCLIP/blob/main/figures/clip_router.png">
    </p>
    <div align="center" style="font-weight: bold">
      CLIP + Router
    </div>
    <p align="center">
      <img src="https://github.com/XavierSpycy/MultiCLIP/blob/main/figures/blip_ml_decoder.png">
    </p>
    <div align="center" style="font-weight: bold">
      BLIP + Anything
    </div>
  </details>
  </details>
    <details>
    <summary>
      <h3><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-929292" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
        <p align="center">
          <img src="assets/growtika-f0JGorLOkw0-unsplash.jpg" width="500" height="auto">
        </p>
        <p>
        Photo by <a href="https://unsplash.com/@growtika?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Growtika</a> on <a href="https://unsplash.com/photos/a-computer-generated-image-of-a-network-and-a-laptop-f0JGorLOkw0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
        </p>
        <details>
        <summary>
          <h3>ðŸŒŸHands-on LoRa: Practical Fine-tuning LLMs using LoRa<a href="https://github.com/XavierSpycy/hands-on-lora">&#x2197;</a></h3>
        </summary>
        <div align="center" style="font-weight: bold;">
          Completed Showcase of LLMs with LoRa
        </div>
        <div align="center">
          <table style="text-align: center;">
              <tr>
                <td>LLM</td>
                <td>No. Parameters</td>
                <td>Task</td>
                <td>LoRa/QLoRa</td>
                <td>Code</td>
              </tr>
              <tr>
                <td>Gemma-IT</td>
                <td>2B</td>
                <td>Text-to-text Generation</td>
                <td>QLoRa</td>
                <td><a href="https://github.com/XavierSpycy/hands-on-lora/tree/main/examples/gemma_text2text">Link</a></td>
              </tr>
              <tr>
                <td>Qwen 2</td>
                <td>1.5B</td>
                <td>Named Entity Recognition</td>
                <td>LoRa</td>
                <td><a href="https://github.com/XavierSpycy/hands-on-lora/tree/main/examples/qwen_ner">Link</a></td>
              </tr>
              <tr>
                <td>Llama 3</td>
                <td>8B</td>
                <td>Cross-Linguistic Adaptation</td>
                <td>LoRa</td>
                <td><a href="https://github.com/XavierSpycy/hands-on-lora/tree/main/examples/llama_chinese">Link</a></td>
              </tr>
          </table>
        </div>
      </details>
      <details>
        <summary>
          <h3>ðŸŒŸLlama3Ops: From LoRa to Deployment with Llama3<a href="https://github.com/XavierSpycy/llama-ops">&#x2197;</a></h3>
        </summary>
        <ul>
        <li><u>Model weights</u>: <a href="https://huggingface.co/XavierSpycy/Meta-Llama-3-8B-Instruct-zh-10k">XavierSpycy/Meta-Llama-3-8B-Instruct-zh-10k</a></li>
        <li><u>Finetuning framework</u>: <code>LLaMA-Factory</code> | <code>PEFT</code> | <code>Unsloth</code> </li>
        <li><u>Qauntization framework</u>: <code>llama.cpp</code> | <code>AutoAWQ</code> | <code>AutoGPTQ</code></li>
        <li><u>Deployment framework</u>: <code>llama.cpp</code> | <code>ollama</code> | <code>TensorRT-LLM</code> & <code>Triton</code> | <code>vLLM</code> </li>
        <li><u>RAG framework</u>: <code>LangChain</code> | <code>LlamaIndex</code></li>
        </ul>
      </details>
  </details>
  <details>
    <summary>
      <h3><img src="http://img.shields.io/badge/-TensorFlow-eee?style=flat-square&logo=tensorflow&logoColor=FF6F00" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
      <details>
        <summary>
          <h3>ðŸŒŸAwesome Tutorials for TensorFlow2<a href="https://github.com/XavierSpycy/Awesome-Tutorials-for-TensorFlow2">&#x2197;</a></h3>
        </summary>
      </details>
  </details>
</details>

<details>
  <summary>
    <h2>ðŸ“„ Certification</h2>
  </summary>
  <div style="text-align: center;">
    <img src="assets/coursera.svg" width="100" height="auto">
  </div>
  <div align="center">
      <table>
          <tr>
            <td>Specialization</td><td>Launcher</td><td>Completion Date</td><td>Credential</td>
          </tr>
          <tr>
            <td><b>Generative Adversarial Networks (GANs)</b></td>
            <td>DeepLearning.AI</td>
            <td>Jun 2024</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/VMERTE79P6FD">Link</a></td>
          </tr>
          <tr>
            <td><b>Natural Language Processing</b></td>
            <td>DeepLearning.AI</td>
            <td>Oct 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/MGL3LJNX3RZK">Link</a></td>
          </tr>
          <tr>
            <td><b>Deep Learning</b></td>
            <td>DeepLearning.AI</td>
            <td>Aug 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/MCHWQ64ZN86Q">Link</a></td>
          </tr>
          <tr>
            <td><b>Mathematics for Machine Learning and Data Science</b></td>
            <td>DeepLearning.AI</td>
            <td>Aug 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/UJQNSGBXB4FL">Link</a></td>
          </tr>
          <tr>
            <td><b>Applied Data Science with Python</b></td>
            <td>University of Michigan</td>
            <td>Jul 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/S77MYG6WQCUS">Link</a></td>
          </tr>
          <tr>
            <td><b>Machine Learning</b></td>
            <td>DeepLearning.AI & Stanford University</td>
            <td>Jul 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/GVJJK3HZRSLZ">Link</a></td>
          </tr>
          <tr>
            <td><b>Mathematics for Machine Learning</b></td>
            <td>Imperial College London</td>
            <td>Jun 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/UHPTL6AM2WHK">Link</a></td>
          </tr>
          <tr>
            <td><b>Expressway to Data Science: Python Programming</b></td>
            <td>University of Colorado Boulder</td>
            <td>Dec 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/D9N32LL56ZE8">Link</a></td>
          </tr>
          <tr>
            <td><b>Python 3 Programming</b></td>
            <td>University of Michigan</td>
            <td>Dec 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/5ZZC4LJULZ83">Link</a></td>
          </tr>
          <tr>
            <td><b>Introduction to Scripting in Python</b></td>
            <td>Rice University</td>
            <td>Nov 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/KN3NPRDUTAFG">Link</a></td>
          </tr>
          <tr>
            <td><b>Statistics with Python</b></td>
            <td>University of Michigan</td>
            <td>Nov 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/2GDKV3UYSTNU">Link</a></td>
          </tr>
          <tr>
            <td><b>Excel Skills for Data Analytics and Visualization</b></td>
            <td>Macquarie University</td>
            <td>Oct 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/R9Y9AFUZURMK">Link</a></td>
          </tr>
          <tr>
            <td><b>Python for Everybody</b></td>
            <td>University of Michigan</td>
            <td>Oct 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/P2L44FCJR9V6">Link</a></td>
          </tr>
          <tr>
            <td><b>Excel Skills for Business</b></td>
            <td>Macquarie University</td>
            <td>Sep 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/PKTDSLULS3SB">Link</a></td>
          </tr>
        </tr>
      </table>
  </div>
  <details>
    <summary><h3>Credentials</h3></summary>
    <img src="assets/certificate-wall-2.jpg">
    <img src="assets/certificate-wall-1.jpg">
  </details>
</details>

<details> 
  <summary>
    <h2>â˜Žï¸ Contact</h2>
  </summary>
  <p>
  If you have any questions or need further information, please don't hesitate to open an issue: <a href="https://github.com/XavierSpycy/XavierSpycy/issues">Ask a Question</a>.
  </p>
  <p align="left">
      <a href="mailto:jixu9182@uni.sydney.edu.au" target="_blank">
          <img align="center" src="assets/outlook.svg" alt="Outlook" height="30" width="30" style="margin-right:10px;"/>
          jixu9182@uni.sydney.edu.au
      </a>
  </p>
  <p align="left">
      <a href="https://www.linkedin.com/in/jiarui-xu-xavierspycy98" target="_blank">
          <img align="center" src="assets/linkedin.svg" alt="LinkedIn" height="30" width="30" style="margin-right:10px;"/>
          Jiarui XU
      </a>
  </p>
</details>

<hr style="width: 60%; margin: auto;">
<h2 style="text-align: center;">Thank you for visiting â¤ï¸</h2>