<img src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&logoColor=white"> <img src="https://komarev.com/ghpvc/?username=XavierSpycy&color=blueviolet">

<img src="assets/header.svg">

<img src="assets/chris-ried-python-crop.jpg">
Photo by <a href="https://unsplash.com/@cdr6934?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Chris Ried</a> on <a href="https://unsplash.com/photos/ieic5Tq8YMk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>

<a><img src="https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg" align="right" height="48" width="48" ></a>

<a href="https://git.io/typing-svg">
    <img src="https://readme-typing-svg.herokuapp.com?color=%2336BCF7&center=true&vCenter=true&width=600&lines=👋++Hi~,+I+am+Jiarui+Xu~;👋++你好～我叫徐嘉瑞～;Welcome+to+my+profile!;欢迎来到我的主页!;Master's+degree+of+Data+Science;数据科学硕士;Machine+learning+specialization;机器学习专项;Python+programming+enthusiast;Python编程爱好者;Patience+and+persistence.;持之以恒。" alt="Typing SVG">
</a>

<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
  <a href="https://github.com/anuraghazra/github-readme-stats" style="margin-right: 10px;">
    <img height="180" src="https://github-readme-stats.vercel.app/api?username=XavierSpycy&show_icons=true&theme=default&hide=issues"/>
  </a>
  <a href="https://github.com/anuraghazra/github-readme-stats">
    <img height="180" src="https://github-readme-stats.vercel.app/api/top-langs/?username=XavierSpycy&layout=donut">
  </a>
</div>

```mermaid
graph TD;
    DomainKnowledge[Domain Knowledge]-->MachineLearning[Machine Learning];
    MachineLearning[Machine Learning]-->StatisticalLearning[Statistical Learning];
    MachineLearning[Machine Learning]-->DeepLearning[Deep Learning];
    DomainKnowledge[Domain Knowledge]-->BackendDevelopment[Backend Development];
    DeepLearning[Deep Learning]-->ImageClassification[Image Classification];
    ImageClassification[Image Classification]-->LabelNoise[Label Noise];
    DeepLearning[Deep Learning]-->NaturalLanguageProcessing[Natural Language Processing];
    NaturalLanguageProcessing[Natural Language Processing]-->TopicModeling[Topic Modeling];
    NaturalLanguageProcessing[Natural Language Processing]-->LLMApplication[LLM Application];
    LLMApplication[LLM Application]-->RAG[Retrieval-Augmented Generation];
    LLMApplication[LLM Application]-->AIAgent[AI Agent];
    DeepLearning[Deep Learning]-->Multimodality[Multimodality];
    Multimodality[Multimodality]-->ImageTextClassification[Image-Text Classification];
    Multimodality[Multimodality]-->VisualQuestionAnswering[Visual Question Answering];
   ```

| |Skills|
|-|-|
|**Domain**| ![Machine](https://img.shields.io/badge/Machine-Learning-01D277?style=flat&logoColor=white&labelColor=ADD8E6) ![Deep Learning](https://img.shields.io/badge/Deep-Learning-01D277?style=flat&logoColor=white&labelColor=0000FF) ![Natural Language Processing](https://img.shields.io/badge/Natural%20Language%20Processing-4C8CBF?style=flat&logoColor=white) ![Software Development](https://img.shields.io/badge/Software%20Development-FF6600?style=flat&logoColor=white) ![Multimodality Learning](https://img.shields.io/badge/Multimodality-Learning-01D277?style=flat&labelColor=lightyellow)|
|Operating Systems|![Linux](https://img.shields.io/badge/Linux-FCC624?logo=linux&logoColor=black) ![Ubuntu](https://img.shields.io/badge/Ubuntu-E95420?logo=ubuntu&logoColor=white) ![macOS](https://img.shields.io/badge/macOS-000000?logo=apple&logoColor=F0F0F0) ![Windows](https://custom-icon-badges.demolab.com/badge/Windows-0078D6?logo=windows11&logoColor=white)|
|**Languages**|![Python](https://img.shields.io/badge/Python-4C8CBF?logo=data:image/svg+xml;base64,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) ![Bash](https://img.shields.io/badge/Bash-4EAA25?logo=gnubash&logoColor=fff) ![Markdown](https://img.shields.io/badge/Markdown-%23000000.svg?logo=markdown&logoColor=white) ![C](https://img.shields.io/badge/C-BDE8F7?logo=data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIzMi4xODU4NTYxMTcyMDE0OSAyMC40NyAyMjMuNjg1MTM2MDk0MTIzMyAyNDcuMDU5OTk5OTk5OTk5OTciIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgd2lkdGg9IjIxMTMiIGhlaWdodD0iMjUwMCI+PHBhdGggZD0iTTI1Mi43MSA5My42MWEyMS42NyAyMS42NyAwIDAgMC0yLjY1LTEwLjg3IDIwLjc0IDIwLjc0IDAgMCAwLTcuODctNy42N1ExOTguNzcgNTAgMTU1LjMyIDI1Yy03LjgtNC41MS0xNS4zNi00LjM1LTIzLjExLjIzQzEyMC42OSAzMiA2MyA2NS4wOSA0NS44MSA3NS4wNmMtNy4wOCA0LjEtMTAuNTIgMTAuMzgtMTAuNTIgMTguNTR2MTAwLjhhMjEuNzcgMjEuNzcgMCAwIDAgMi41NSAxMC42NiAyMC42MyAyMC42MyAwIDAgMCA4IDcuODhjMTcuMTkgMTAgNzQuODkgNDMuMDUgODYuNDEgNDkuODUgNy43NSA0LjU4IDE1LjMxIDQuNzQgMjMuMTIuMjNxNDMuNDEtMjUuMDggODYuODctNTAuMDlhMjAuNjMgMjAuNjMgMCAwIDAgOC03Ljg4IDIxLjc3IDIxLjc3IDAgMCAwIDIuNTUtMTAuNjZWOTMuNjF6IiBmaWxsPSIjMDA0NDgyIi8+PHBhdGggZD0iTTI1Mi43MyAxOTQuNGEyMS43MiAyMS43MiAwIDAgMS0yLjU1IDEwLjY2IDE4LjU4IDE4LjU4IDAgMCAxLTEuNDUgMi4yNEwxNDQgMTQ0bDk4LjE5LTY4LjkzYTIwLjcyIDIwLjcyIDAgMCAxIDcuODYgNy42NyAyMS41NyAyMS41NyAwIDAgMSAyLjY2IDEwLjg3Yy4wMiAzMy42LjAyIDEwMC43OS4wMiAxMDAuNzl6IiBmaWxsPSIjMDA1OTljIi8+PHBhdGggZD0iTTI1MC4wNSA4Mi43NEwzNy44MSAyMDUuMDZhMjEuNzUgMjEuNzUgMCAwIDEtMi41My0xMC42NVY5My42YzAtOC4xNiAzLjQ1LTE0LjQ0IDEwLjUyLTE4LjU0QzYzIDY1LjA5IDEyMC42OSAzMiAxMzIuMjIgMjUuMjFjNy43My00LjU4IDE1LjMtNC43NCAyMy4xLS4yM3E0My40MSAyNS4wOCA4Ni44NyA1MC4wOWEyMC43MiAyMC43MiAwIDAgMSA3Ljg2IDcuNjd6IiBmaWxsPSIjNjU5YWQyIi8+PHBhdGggZD0iTTE0OC4yIDE4NC43MmEzOS45MSAzOS45MSAwIDAgMS0zNS0yMC42M3EtLjUzLS45NC0xLTEuOTJBMzkuOTQgMzkuOTQgMCAwIDEgMTc5IDExOS40Yy41My42NCAxIDEuMzEgMS41MyAyIC4yNC4zMy40OC42Ni43IDFsMzUuMDctMjAuMnEtMS4yOC0yLjA2LTIuNjgtNGMtLjQ5LS42OS0xLTEuMzUtMS40OC0yQTc5LjkgNzkuOSAwIDAgMCA3OCAxODEuOTJjLjM0LjY0LjY5IDEuMjcgMSAxLjlhNzkuOTEgNzkuOTEgMCAwIDAgMTM2Ljg2IDMuNjJsLTM0LjI5LTIwLjczYTM5Ljg4IDM5Ljg4IDAgMCAxLTMzLjM3IDE4LjAxeiIgZmlsbD0iI2ZmZiIvPjwvc3ZnPg==)|
|**DL Frameworks**| ![PyTorch](http://img.shields.io/badge/-PyTorch-4F004F?style=flat&logo=pytorch&logoColor=FF0000) ![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-929292) ![TensorFlow](http://img.shields.io/badge/-TensorFlow-eee?style=flat&logo=tensorflow&logoColor=FF6F00) ![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=flat&logo=Keras&logoColor=white)|
| **LLM Applications**|![LangChain Badge](https://img.shields.io/badge/LangChain-1C3C3C?logo=langchain&logoColor=fff&style=flat) ![Ollama Badge](https://img.shields.io/badge/Ollama-000?logo=ollama&logoColor=fff&style=flat)|
|**ML Library**| ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=flat&logo=scikit-learn&logoColor=white&labelColor=blue) |
|**Scientific Computing**| ![NumPy](https://img.shields.io/badge/-NumPy-4C8CBF?style=flat&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/-Pandas-000077?style=flat&logo=pandas&logoColor=white) ![SciPy](https://img.shields.io/badge/-SciPy%20-white?style=flat&logo=scipy&logoColor=004091)|
|**Web Deployment**|![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat&logo=fastapi) ![Django](https://img.shields.io/badge/django-%23092E20.svg?style=flat&logo=django&logoColor=white)|
|**Database**| ![MySQL](https://img.shields.io/badge/MySQL-white?logo=data:image/svg+xml;base64,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) ![MongoDB](https://img.shields.io/badge/MongoDB-%234ea94b.svg?style=flat&logo=mongodb&logoColor=white)|
|**Version Control**|![Git](https://img.shields.io/badge/Git-F05032?logo=git&logoColor=fff)|
|**Containerization**|![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=fff)|
|**Self-developed Package**| [![mlforce](https://img.shields.io/badge/mlforce-green)](https://pypi.org/project/mlforce/) ![Machine Learning Force](https://img.shields.io/pypi/v/mlforce)|
|**Statistic Tools**| ![R programming](https://img.shields.io/badge/R-525252?style=flat&logo=R) ![R Studio](https://img.shields.io/badge/RStudio-27338e?style=flat&logo=RStudio&logoColor=white)|
| **Visualization**| ![Matplotlib](https://img.shields.io/badge/matplotlib-white?logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjgiIGhlaWdodD0iMTI4IiBzdHJva2U9IiM3NzciIGZpbGwtb3BhY2l0eT0iLjgiPgo8cGF0aCBmaWxsPSIjRkZGIiBkPSJtNjMsMWE2Myw2MyAwIDEsMCAyLDB6bTAsMTRhNDksNDkgMCAxLDAgMiwwem0wLDE0YTM1LDM1IDAgMSwwCjIsMHptMCwxNGEyMSwyMSAwIDEsMCAyLDB6bTAsMTRhNyw3IDAgMSwwIDIsMHptNjQsN0gxbTEwOC00NS05MCw5MG05MCwwLTkwLTkwbTQ1LTE4djEyNiIvPgo8cGF0aCBmaWxsPSIjRjYwIiBkPSJtNTAsOC0yMCwxMCA2OCw5MiAxMC0xMEw2NCw2NHoiLz4KPHBhdGggZmlsbD0iI0ZDMCIgZD0ibTE3LDUwdjI4TDY0LDY0eiIvPgo8cGF0aCBmaWxsPSIjN0Y3IiBkPSJtNjQsNjQgNiwzNUg1OHoiLz4KPHBhdGggZmlsbD0iI0NGMyIgZD0ibTY0LDY0IDEzLTQwIDksNXoiLz4KPHBhdGggZmlsbD0iIzA0RiIgZD0ibTY0LDY0IDE0LTYgMSw0emwtMjYsMTMgMyw0eiIvPgo8L3N2Zz4=) ![Tableau](https://img.shields.io/badge/-Tableau-FF0000?style=flat&logo=tableau&logoColor=white) ![PowerBI](https://img.shields.io/badge/-PowerBI-FF6F00?style=flat&logo=powerbi&logoColor=white) ![D3](https://img.shields.io/badge/-D3.js%20-EEEE00?style=flat&logo=d3.js&logoColor=white) ![Tulip](https://img.shields.io/badge/-Tulip%20-00AA00?style=flat&logo=Tulip&logoColor=white) ![yEd](https://img.shields.io/badge/-yEd%20-00000FF?style=flat&logo=yEd&logoColor=white) ![Gephi](https://img.shields.io/badge/-Gephi%20-4F004F?style=flat&logo=Gephid&logoColor=white)|
|**Integrated Development Environment**|![Visual Studio Code](https://custom-icon-badges.demolab.com/badge/Visual%20Studio%20Code-0078d7.svg?logo=vsc&logoColor=white) ![Python IDLE](https://img.shields.io/badge/Python%20IDLE-3776AB?logo=python&logoColor=fff)|

<details>
  <summary><h2>📖 Curriculum Vitae</h2></summary>
    <p>
    <a href="assets/Jiarui_XU_CV.pdf">English</a> | 
    <a href="assets/Jiarui_XU_CV__zh__CN_.pdf">中文版</a>
    </p>
</details>

<details>
  <summary><h2>🌊 Experiences</h2></summary>
  <ul>
    <li>
      Ressearch Interests : LLM Applications / Multimodality Learning
    </li>
    <li>
      Research:
      <ol>
        <li>
          Cross-modal medical image representation learning (<u><em>USYD Engineering VRI Scholarship</em></u>)
        </li>
        <li>
          <em>Top</em>ic <em>M</em>odeling for the <em>E</em>volution through <em>D</em>escriptions of <em>A</em>pplications <em>L</em>ongitudina (<em>TopMEDAL</em>)
        </li>
      </ol>
    </li>
    <li>
      Internship:
      <ul>
        <li>
        <code>LLM Algorithm Intern</code> &#x40; <img src="https://img.shields.io/badge/Giant Network-grey?logoColor=#FFD700">
          <ul>
            <li>AI Lab</li>
            <li>2024.08 ~ 2024.11</li>
          </ul>
        </li>
      </ul>
      <ul>
        <li>
          <code>Vacation Research Intern</code> &#x40; <img src="https://img.shields.io/badge/University%20of%20Sydney-white?logo=data:image/svg+xml;base64,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">
          <ul>
            <li>
              Faculty of Engineering
            </li>
            <li>
              2024.06 ~ 2024.07
            </li>
          </ul>
        </li>
        <li>
          <code>AIGC Algorithm Intern</code> &#x40; <img src="https://img.shields.io/badge/Funplus-orange?logo=data:image/svg+xml;base64,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">
        </li>
        <ul>
          <li>
            AI Tech
          </li>
          <li>
            2023.12 ~ 2024.02
          </li>
        </ul>
      </ul>
  </ul>
</details>

<details>
  <summary>
    <h2>🚀 Projects</h2>
  </summary>
  <details>
    <summary>
      <h3><img src="https://img.shields.io/badge/NumPy-blue?style=flat&logo=numpy" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
    <p align="center">
      <img src="assets/google-deepmind.jpg" width="500" height="auto">
    </p>
    <p>
      Photo by <a href="https://unsplash.com/@googledeepmind?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Google DeepMind</a> on <a href="https://unsplash.com/photos/LaKwLAmcnBc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
    </p>
    <details>
      <summary id="star-self-developed-library-using-numpy">
        <h3>🌟Self-Developed Library using NumPy</h3><a href="https://github.com/XavierSpycy/MLForce">&#x2197;</a>
      </summary>
      <p>
        My NumPy-based projects have been successfully integrated into my own open-source Python library, named <a href="https://pypi.org/project/mlforce/"><code>MLForce</code></a>. This library is also readily accessible on the <a href="https://pypi.org/project/mlforce">PyPI Community</a>.
      </p>
    </details>
    <details>
      <summary>
        <h3>🌟Multilayer Perceptron from Scratch using NumPy<a href="https://github.com/XavierSpycy/NumPyMultilayerPerceptron">&#x2197;</a></h3>
        <p>
      </summary>
        A robust implementation of multilayer perceptrons, entirely built upon the powerful NumPy library.
        </p>
        <p>Advantages of our implementation:
          <ul>
            <li>
              <details>
                <summary>Easy to construct</summary>
                <p>
                  <pre><code class="language-python">layers = [
      Input(input_dim=2),
      Dense(units=4, activation='leaky_relu', init='kaiming_normal', init_params={'mode': 'out'}),
      Dense(units=3, activation='hardswish', init='xavier_normal'),
      Dense(units=2, activation='relu', init='kaiming_normal', init_params={'mode': 'in'}),
      Dense(units=1, activation='tanh', init='xavier_uniform')
  ]
  mlp = MultilayerPerceptron(layers)</code></pre>
                </p>
              </details>
            </li>
            <li>
              <details>
                <summary>Easy and stable to train</summary>
                <p>
                  <pre><code class="language-python">mlp.compile(optimizer='Adam',
              metrics=['MeanSquareError'])
  mlp.fit(X, y, epochs=3, batch_size=8, use_progress_bar=True)</code></pre>
                </p>
                <p align="center">
                  <img src="https://github.com/XavierSpycy/NumPyMultilayerPerceptron/blob/main/figures/toy_loss.png">
                </p>
                <div align="center" style="font-weight: bold;">
                  Loss
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary>
                  Great results
                </summary>
                <p align="center">
                  <img src="https://github.com/XavierSpycy/NumPyMultilayerPerceptron/blob/main/figures/toy_decision_boundary.png">
                </p>
                <div align="center" style="font-weight: bold;">
                  Decision boundary
                </div>
              </details>
            </li>
            <li>
              <details>
                <summary>
                  Capability of dealing with complex datasets (10 classes, 128 features, 50,000 samples)
                </summary>
                <p align="center">
                  <img src="https://github.com/XavierSpycy/NumPyMultilayerPerceptron/blob/main/figures/10classes.png">
                </p>
                <div align="center" style="font-weight: bold;">
                  Smooth optimization procedure in 600 epochs
                </div>
              </details>
            </li>
    </details>

  <details>
    <summary>
      <h3>🌟Non-negative Matrix Factorization using NumPy<a href="https://github.com/XavierSpycy/NumPyNMF">&#x2197;</a></h3>
    </summary>
    <p>
      This project implements nine different Non-negative Matrix Factorization (NMF) algorithms and compares the robustness of each algorithm to five various types of noise in real-world data applications.
    </p>
    <ul>
      <li>
      <details>
        <summary>
          Well-reconstructed effects
        </summary>
        <p align="center">
          <img src="https://github.com/XavierSpycy/NumPyNMF/blob/main/figures/pin.png">
        </p>
        <div align="center" style="font-weight: bold;">
          Image reconstruction
        </div>
      </details>
      </li>
      <li>
      <details>
        <summary>Sufficient experiments</summary>
        <p>
          We conduct a seires of experiments, thus when developing your own algorithms, these results could act as a baseline. The results of the experiments (2 datasets &times; 5 noise types &times; 2 noise levels &times; 5 random seeds implicitly) are displayed in the repository.
        </p>
      </details>
      </li>
      <li>
      <details>
        <summary>Flexible development</summary>
        <p>
          Our development framework empowers you to effortlessly create your own NMF algorithms with minimal Python scripting.
        </p>
      </details>
      </li>
      <li>
      <details>
        <summary>Mature pipeline</summary>
        <p>
          Our framework offers well-established pipelines, accommodating both standard and customized NMF tests. 
        </p>
        <p>
          For personalized NMF models, the <code>nmf</code> parameter accepts a <code>BasicNMF</code> object. You can seamlessly insert your own NMF model into our pipeline to evaluate its performance.
        </p>
      </details>
      </li>
      <li>
      <details>
        <summary>Multiprocessing experiments</summary>
        <p>
          We've harnessed the power of multiprocessing for extensive experiments, significantly enhancing efficiency. This approach has halved the overall experiment duration, reducing it to 30% ~ 50% of the time it would take to run each experiment sequentially.
        </p>
        <p>
          For a comprehensive analysis of your algorithm, our platform enables conducting multiple experiments across various datasets:
        </p>
        <pre><code>from algorithm.pipeline import Experiment

  exp = Experiment()
  exp.choose('L1NormRegularizedNMF')
  exp.execute()</code></pre>
      </details>
      </li>
      <li>
      <details>
        <summary>Interactive algorithm interface</summary>
        <p align="center">
          <img src="https://github.com/XavierSpycy/NumPyNMF/blob/main/figures/app_screen_shoot.jpg">
        </p>
        <p align="center">
          <img src="https://github.com/XavierSpycy/NumPyNMF/blob/main/figures/app_screen_shoot_2.jpg">
        </p>
        <div align="center" style="font-weight: bold;">
          Demo
        </div>
        <p>
          Note that the initial parameter in these experiments can also be <code>BasicNMF</code> object, allowing the direct integration of your custom NMF model for thorough evaluation and testing.
        </p>
      </details>
      </li>
    </ul>
  <b>
    DON'T HESITATE TO DEVELOP YOUR OWN ALGORITHM!!!
  </b>
  </details>
  </details>
  <details>
    <summary>
      <h3><img src="http://img.shields.io/badge/-PyTorch-4F004F?style=flat-square&logo=pytorch&logoColor=FF0000" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
    <p align="center">
      <img src="assets/alex-knight-machinelearning.jpg" width="500" height="auto">
    </p>
    Photo by <a href="https://unsplash.com/@agk42?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Alex Knight</a> on <a href="https://unsplash.com/photos/white-robot-near-brown-wall-2EJCSULRwC8?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
    <details>
      <summary id="star-emnist-handwritten-character-classification">
        <h3>🌟EMNIST Handwritten Character Classification</h3><a href="https://github.com/XavierSpycy/EMNIST-Classifier">&#x2197;</a>
      </summary>
      <p>
        This project aims to reproduce various convolutional neural networks and modify them to our specific requirements.
      </p>
      <div align="center">
    <table style="text-align: center;">
      <caption>Performance of different CNNs on the training set</caption>
      <tr>
        <td></td>
        <td align="center">AlexNet</td>
        <td align="center">VGGNet</td>
        <td align="center">SpinalNet</td>
        <td align="center">ResNet</td>
      </tr>
      <tr>
        <td align="center">Accuracy</td>
        <td align="center">87.95%</td>
        <td align="center">89.80%</td>
        <td align="center">87.15%</td>
        <td align="center">89.28%</td>
      </tr>
      <tr>
        <td align="center">Precision</td>
        <td align="center">87.62%</td>
        <td align="center">90.01%</td>
        <td align="center">86.18%</td>
        <td align="center">89.24%</td>
      </tr>
      <tr>
        <td align="center">Recall</td>
        <td align="center">87.95%</td>
        <td align="center">89.80%</td>
        <td align="center">87.15%</td>
        <td align="center">89.28%</td>
      </tr>
      <tr>
        <td align="center">F1 score</td>
        <td align="center">86.59%</td>
        <td align="center">88.42%</td>
        <td align="center">85.28%</td>
        <td align="center">88.30%</td>
      </tr>
    </table>
    </div>
    <div align="center">
    <table style="text-align: center;">
      <caption>Performance of different CNNs on the test set</caption>
      <tr>
        <td></td>
        <td align="center">AlexNet</td>
        <td align="center">VGGNet</td>
        <td align="center">SpinalNet</td>
        <td align="center">ResNet</td>
      </tr>
      <tr>
        <td align="center">Accuracy</td>
        <td align="center">86.96%</td>
        <td align="center">87.24%</td>
        <td align="center">85.92%</td>
        <td align="center">86.88%</td>
      </tr>
      <tr>
        <td align="center">Precision</td>
        <td align="center">85.55%</td>
        <td align="center">86.43%</td>
        <td align="center">85.92%</td>
        <td align="center">86.88%</td>
      </tr>
      <tr>
        <td align="center">Recall</td>
        <td align="center">86.96%</td>
        <td align="center">87.24%</td>
        <td align="center">85.92%</td>
        <td align="center">86.88%</td>
      </tr>
      <tr>
        <td align="center">F1 score</td>
        <td align="center">85.58%</td>
        <td align="center">85.66%</td>
        <td align="center">84.07%</td>
        <td align="center">85.68%</td>
      </tr>
    </table>
    </div>
    <p align="center">
      <img src="https://github.com/XavierSpycy/EMNIST-Classifier/blob/main/outputs/predictions_short.png">
    </p>
    <div align="center" style="font-weight: bold;">
      Effects of VGGNet
    </div>
    </details>
    <details>
    <summary>
      <h3>🌟CAT: A Visual-Text Multimodal Classifier</h3><a href="https://github.com/XavierSpycy/CAT-ImageTextIntegrator">&#x2197;</a>
    </summary>
    <p>
      This project involves a multi-label multi-classification problem. We deployed four pre-trained image models and two pre-trained text models. To enhance performance, we developed 12 multi-modal models using self-attention and cross-attention mechanisms. The project poster showcases some valuable techniques and intriguing discoveries.
    </p>
    <p align="center">
      <img src="https://github.com/XavierSpycy/CAT-ImageTextIntegrator/blob/main/outcomes/CAT-2.jpeg">
    </p>
    <div align="center" style="font-weight: bold;">
      CAT (Convolution, Attention and Transformer) architecture
    </div>
    <p align="center">
      <img src="https://github.com/XavierSpycy/CAT-ImageTextIntegrator/blob/main/outcomes/poster.jpg">
    </p>
    <div align="center" style="font-weight: bold;">
      Project Poster
    </div>
  </details>
  <details>
    <summary>
      <h3>🌟Robust Traniners for Noisy Labels</h3><a href="https://github.com/XavierSpycy/Robust-Trainers-for-Noisy-Labels">&#x2197;</a>
    </summary>
    <p>
      This project is an experimental repository focusing on dealing with datasets containing a high level of noisy labels (50% and above). This repository features experiments conducted on the <code>FashionMNIST</code> and <code>CIFAR</code> datasets using the <code>ResNet34</code> as the baseline classifier.
    </p>
    <p>
      The repository explores various training strategies (<code>Trainer</code> objects), including <code>ForwardLossCorrection</code>, <code>CoTeaching</code>, <code>JoCoR</code>, and <code>O2UNet</code>. Specifically, for datasets with unknown transition matrices, <code>DualT</code> is employed as the Transition Matrix Estimator.
    </p>
    <ul>
      <li>
        <details>
          <summary>Meaningful Loss Trends</summary>
          <p align="center">
            <img src="https://github.com/XavierSpycy/Robust-Trainers-for-Noisy-Labels/blob/main/figures/loss_correction_trend.png">
          </p>
          <div align="center" style="font-weight: bold;">
            Loss Trend 1
          </div>
          <p align="center">
            <img src="https://github.com/XavierSpycy/Robust-Trainers-for-Noisy-Labels/blob/main/figures/co_teaching_trend.png">
          </p>
          <div align="center" style="font-weight: bold;">
            Loss Trend 2
          </div>
        </details>
      </li>
      <li>
        <details>
          <summary>Persuasive Results</summary>
          <div align="center">
            <h5>FashionMNIST0.5</h5>
              <table>
                <tr>
                  <th colspan="3">Actual Transition Matrix</th>
                  <th colspan="3">Estimated Transition Matrix</th>
                </tr>
                <tr>
                  <td>0.5</td><td>0.2</td><td>0.3</td><td>0.473</td><td>0.209</td><td>0.309</td>
                </tr>
                <tr>
                  <td>0.3</td><td>0.5</td><td>0.2</td><td>0.306</td><td>0.485</td><td>0.232</td>
                </tr>
                <tr>
                  <td>0.2</td><td>0.3</td><td>0.5</td><td>0.221</td><td>0.306</td><td>0.460</td>
                </tr>
              </table>
          </div>
          <div align="center">
            <h5>FashionMNIST0.6</h5>
              <table>
                <tr>
                    <th colspan="3">Actual Transition Matrix</th>
                    <th colspan="3">Estimated Transition Matrix</th>
                </tr>
                <tr>
                  <td>0.4</td><td>0.3</td><td>0.3</td><td>0.407</td><td>0.295</td><td>0.298</td>
                </tr>
                <tr>
                  <td>0.3</td><td>0.4</td><td>0.3</td><td>0.297</td><td>0.394</td><td>0.308</td>
                </tr>
                <tr>
                  <td>0.3</td><td>0.3</td><td>0.4</td><td>0.301</td><td>0.310</td><td>0.388</td></tr>
                </tr>
              </table>
          </div>
        </details>
      </li>
    </ul>
  </details>
  <details>
    <summary>
      <h3>
        🌟Transformers for Tabular Data<a href="https://github.com/XavierSpycy/tabtransformers">&#x2197;</a>
      </h3>
    </summary>
    <p>
      A PyTorch-based implementation that leverages Transformer architectures to enhance the handling and design of tabular data.
    </p>
  </details>
  <details>
    <summary>
      <h3>🌟MultiCLIP: Multimodal-Multilabel-Multistage Classification using Language Image Pre-training<a href="https://github.com/XavierSpycy/MultiCLIP">&#x2197;</a></h3>
    </summary>
    <p>
      A framework for multimodal-multilabel-multistage classification utilizing advanced pretrained models like CLIP and BLIP. 
    </p>
    <p>
      Diagrams of implementation:
    </p>
    <p align="center">
      <img src="https://github.com/XavierSpycy/MultiCLIP/blob/main/figures/clip_router.png">
    </p>
    <div align="center" style="font-weight: bold">
      CLIP + Router
    </div>
    <p align="center">
      <img src="https://github.com/XavierSpycy/MultiCLIP/blob/main/figures/blip_ml_decoder.png">
    </p>
    <div align="center" style="font-weight: bold">
      BLIP + Anything
    </div>
  </details>
  </details>
    <details>
    <summary>
      <h3><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-929292" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
        <p align="center">
          <img src="assets/growtika-f0JGorLOkw0-unsplash.jpg" width="500" height="auto">
        </p>
        <p>
        Photo by <a href="https://unsplash.com/@growtika?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Growtika</a> on <a href="https://unsplash.com/photos/a-computer-generated-image-of-a-network-and-a-laptop-f0JGorLOkw0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
        </p>
        <details>
        <summary>
          <h3>🌟Hands-on LoRa: Practical Fine-tuning LLMs using LoRa<a href="https://github.com/XavierSpycy/hands-on-lora">&#x2197;</a></h3>
        </summary>
        <div align="center" style="font-weight: bold;">
          Completed Showcase of LLMs with LoRa
        </div>
        <div align="center">
          <table style="text-align: center;">
              <tr>
                <td>LLM</td>
                <td>No. Parameters</td>
                <td>Task</td>
                <td>LoRa/QLoRa</td>
                <td>Code</td>
              </tr>
              <tr>
                <td>Gemma-IT</td>
                <td>2B</td>
                <td>Text-to-text Generation</td>
                <td>QLoRa</td>
                <td><a href="https://github.com/XavierSpycy/hands-on-lora/tree/main/examples/gemma_text2text">Link</a></td>
              </tr>
              <tr>
                <td>Qwen 2</td>
                <td>1.5B</td>
                <td>Named Entity Recognition</td>
                <td>LoRa</td>
                <td><a href="https://github.com/XavierSpycy/hands-on-lora/tree/main/examples/qwen_ner">Link</a></td>
              </tr>
              <tr>
                <td>Llama 3</td>
                <td>8B</td>
                <td>Cross-Linguistic Adaptation</td>
                <td>LoRa</td>
                <td><a href="https://github.com/XavierSpycy/hands-on-lora/tree/main/examples/llama_chinese">Link</a></td>
              </tr>
          </table>
        </div>
      </details>
      <details>
        <summary>
          <h3>🌟Llama3Ops: From LoRa to Deployment with Llama3<a href="https://github.com/XavierSpycy/llama-ops">&#x2197;</a></h3>
        </summary>
        <ul>
        <li><u>Model weights</u>: <a href="https://huggingface.co/XavierSpycy/Meta-Llama-3-8B-Instruct-zh-10k">XavierSpycy/Meta-Llama-3-8B-Instruct-zh-10k</a></li>
        <li><u>Finetuning framework</u>: <code>LLaMA-Factory</code> | <code>PEFT</code> | <code>Unsloth</code> </li>
        <li><u>Qauntization framework</u>: <code>llama.cpp</code> | <code>AutoAWQ</code> | <code>AutoGPTQ</code></li>
        <li><u>Deployment framework</u>: <code>llama.cpp</code> | <code>ollama</code> | <code>TensorRT-LLM</code> & <code>Triton</code> | <code>vLLM</code> </li>
        <li><u>RAG framework</u>: <code>LangChain</code> | <code>LlamaIndex</code></li>
        </ul>
      </details>
  </details>
  <details>
    <summary>
      <h3><img src="http://img.shields.io/badge/-TensorFlow-eee?style=flat-square&logo=tensorflow&logoColor=FF6F00" style="vertical-align: middle;"> <span style="display: inline-block; transform: rotate(220deg);">&#x27A3;</span></h3>
    </summary>
      <details>
        <summary>
          <h3>🌟Awesome Tutorials for TensorFlow2<a href="https://github.com/XavierSpycy/Awesome-Tutorials-for-TensorFlow2">&#x2197;</a></h3>
        </summary>
      </details>
  </details>
</details>

<details>
  <summary>
    <h2>📄 Certification</h2>
  </summary>
  <div style="text-align: center;">
    <img src="assets/coursera.svg" width="100" height="auto">
  </div>
  <div align="center">
      <table>
          <tr>
            <td>Specialization</td><td>Launcher</td><td>Completion Date</td><td>Credential</td>
          </tr>
          <tr>
            <td><b>Generative Adversarial Networks (GANs)</b></td>
            <td>DeepLearning.AI</td>
            <td>Jun 2024</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/VMERTE79P6FD">Link</a></td>
          </tr>
          <tr>
            <td><b>Natural Language Processing</b></td>
            <td>DeepLearning.AI</td>
            <td>Oct 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/MGL3LJNX3RZK">Link</a></td>
          </tr>
          <tr>
            <td><b>Deep Learning</b></td>
            <td>DeepLearning.AI</td>
            <td>Aug 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/MCHWQ64ZN86Q">Link</a></td>
          </tr>
          <tr>
            <td><b>Mathematics for Machine Learning and Data Science</b></td>
            <td>DeepLearning.AI</td>
            <td>Aug 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/UJQNSGBXB4FL">Link</a></td>
          </tr>
          <tr>
            <td><b>Applied Data Science with Python</b></td>
            <td>University of Michigan</td>
            <td>Jul 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/S77MYG6WQCUS">Link</a></td>
          </tr>
          <tr>
            <td><b>Machine Learning</b></td>
            <td>DeepLearning.AI & Stanford University</td>
            <td>Jul 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/GVJJK3HZRSLZ">Link</a></td>
          </tr>
          <tr>
            <td><b>Mathematics for Machine Learning</b></td>
            <td>Imperial College London</td>
            <td>Jun 2023</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/UHPTL6AM2WHK">Link</a></td>
          </tr>
          <tr>
            <td><b>Expressway to Data Science: Python Programming</b></td>
            <td>University of Colorado Boulder</td>
            <td>Dec 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/D9N32LL56ZE8">Link</a></td>
          </tr>
          <tr>
            <td><b>Python 3 Programming</b></td>
            <td>University of Michigan</td>
            <td>Dec 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/5ZZC4LJULZ83">Link</a></td>
          </tr>
          <tr>
            <td><b>Introduction to Scripting in Python</b></td>
            <td>Rice University</td>
            <td>Nov 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/KN3NPRDUTAFG">Link</a></td>
          </tr>
          <tr>
            <td><b>Statistics with Python</b></td>
            <td>University of Michigan</td>
            <td>Nov 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/2GDKV3UYSTNU">Link</a></td>
          </tr>
          <tr>
            <td><b>Excel Skills for Data Analytics and Visualization</b></td>
            <td>Macquarie University</td>
            <td>Oct 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/R9Y9AFUZURMK">Link</a></td>
          </tr>
          <tr>
            <td><b>Python for Everybody</b></td>
            <td>University of Michigan</td>
            <td>Oct 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/P2L44FCJR9V6">Link</a></td>
          </tr>
          <tr>
            <td><b>Excel Skills for Business</b></td>
            <td>Macquarie University</td>
            <td>Sep 2022</td>
            <td><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/PKTDSLULS3SB">Link</a></td>
          </tr>
        </tr>
      </table>
  </div>
  <details>
    <summary><h3>Credentials</h3></summary>
    <div style="text-align: center;">
      <img src="https://img.shields.io/badge/Coursera-0056D2?logo=coursera&logoColor=fff">
    </div>
    <img src="assets/certificate-wall-2.jpg">
    <img src="assets/certificate-wall-1.jpg">
  </details>
</details>

<details> 
  <summary>
    <h2>☎️ Contact</h2>
  </summary>
  <p>
  If you have any questions or need further information, please don't hesitate to open an issue: <a href="https://github.com/XavierSpycy/XavierSpycy/issues">Ask a Question</a>.
  </p>
  <p align="left">
      <a href="mailto:jixu9182@uni.sydney.edu.au" target="_blank">
          <img align="center" src="assets/outlook.svg" alt="Outlook" height="30" width="30" style="margin-right:10px;"/>
          jixu9182@uni.sydney.edu.au
      </a>
  </p>
  <p align="left">
      <a href="https://www.linkedin.com/in/jiarui-xu-xavierspycy98" target="_blank">
          <img align="center" src="assets/linkedin.svg" alt="LinkedIn" height="30" width="30" style="margin-right:10px;"/>
          Jiarui XU
      </a>
  </p>
</details>

<hr style="width: 60%; margin: auto;">
<h2 style="text-align: center;">Thank you for visiting ❤️</h2>